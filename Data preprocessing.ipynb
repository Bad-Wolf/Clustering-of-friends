{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from functools import partial\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME = \"Павел Богданов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(filepath, friend_name=True):\n",
    "    \"\"\"\n",
    "    Reads facebook messenger's JSON file and returns a pandas Dataframe.\n",
    "    \n",
    "    Doesn't return a dataframe if the participants are more\n",
    "    than two people(no group chats).\n",
    "    \n",
    "    Works only on the \"Messages\" json files downloaded through\n",
    "    Facebook's \"Download Your Information\" section.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : string\n",
    "        Filepath to the JSON file.\n",
    "    friend_name : boolean, default True\n",
    "        If True, adds an aditional column \"friend_name\" to the df.\n",
    "    Returns\n",
    "    -------\n",
    "    result : Dataframe        \n",
    "    \"\"\"\n",
    "    # Fixes bad encoding\n",
    "    fix_mojibake_escapes = partial(re.compile(rb'\\\\u00([\\da-f]{2})').sub, lambda m: bytes.fromhex(m.group(1).decode()))\n",
    "    \n",
    "    # Need to read as binary to decode correctly\n",
    "    with open(filepath, 'rb') as file:    \n",
    "        repaired = fix_mojibake_escapes(file.read())\n",
    "        data = json.loads(repaired.decode('utf8'), strict=False)\n",
    "        \n",
    "        # No group chats!\n",
    "        if len(data['participants']) == 2:\n",
    "            result = pd.DataFrame.from_dict(data['messages'])\n",
    "            \n",
    "            # Additional column\n",
    "            if friend_name:\n",
    "                participants = pd.Series(data['participants']).apply(pd.Series)\n",
    "                for name in participants.name:\n",
    "                    if not name == ME:\n",
    "                        result['friend_name'] = name\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(\"messages/inbox/*/message_1.json\")\n",
    "data = pd.concat((json_to_df(filename) for filename in all_files), ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.timestamp_ms = pd.to_datetime(data.timestamp_ms, unit='ms')\n",
    "data = data.sort_values('timestamp_ms')\n",
    "data = data.drop_duplicates('timestamp_ms')\n",
    "data = data.set_index('timestamp_ms', verify_integrity=True)\n",
    "data.index.names = ['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = data[(data.type=='Generic') | (data.type=='Share')][['sender_name', 'content', 'friend_name', 'type', 'share', 'reactions']]\n",
    "mess.content.dropna(inplace=True)\n",
    "mess.sender_name = mess.sender_name.astype('category')\n",
    "mess.friend_name = mess.friend_name.astype('category')\n",
    "mess.type = mess.type.astype('category')\n",
    "mess.content = mess.content.str.lower()\n",
    "mess.content = mess.content.replace(np.nan, '0')\n",
    "mess = mess[mess.content!='0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess.content = mess.content.str.replace(r'(https?:\\/\\/\\S*)', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space split and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_mess = mess.copy()\n",
    "tokenized_mess = mess.copy()\n",
    "\n",
    "space_mess.content = space_mess.content.str.split()\n",
    "space_mess.content.dropna(inplace=True)\n",
    "\n",
    "tokenized_mess.content = tokenized_mess.content.apply(word_tokenize)\n",
    "tokenized_mess.content.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(dataframe):\n",
    "    rows = list()\n",
    "    for row in dataframe[['sender_name', 'content', 'timestamp']].iterrows():\n",
    "        r = row[1]\n",
    "        for word in r.content:\n",
    "            rows.append((r.sender_name, word, r.timestamp))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=['sender_name', 'word', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_mess.reset_index(inplace=True)\n",
    "tokenized_mess.reset_index(inplace=True)\n",
    "\n",
    "words_by_space = word_split(space_mess)\n",
    "words_by_tokenizer = word_split(tokenized_mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_space.to_csv(\"words_by_space\", index=False)\n",
    "words_by_tokenizer.to_csv(\"words_by_tokenizer\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
